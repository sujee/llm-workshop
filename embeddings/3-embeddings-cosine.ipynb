{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Cosine Distance of Embedding Vectors\n",
    "\n",
    "We are going to calculate cosine distance of embedding vectors\n",
    "\n",
    "![](../media/embeddings-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Setup (GPU)\n",
    "\n",
    "GPUs can really accellerate LLM / embedding operations.  Let's make sure we are using GPUs if we have them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA/GPU:  True\n",
      "device  0 NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "## To disable GPU and experiment, uncomment the following line\n",
    "## Normally, you would want to use GPU, if one is available.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "print (\"using CUDA/GPU: \", torch.cuda.is_available())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(\"device \", i , torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Calculate Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine between\n",
      "That is a happy person\n",
      "That is a very happy person\n",
      "0.9759863615036011\n",
      "\n",
      "Cosine between\n",
      "That is a happy person\n",
      "Bad traffic!\n",
      "0.43310314416885376\n"
     ]
    }
   ],
   "source": [
    "# Requires sentence_transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# model_name = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "model_name = 'BAAI/bge-small-en-v1.5'\n",
    "\n",
    "sentences = ['That is a happy person', 'That is a very happy person', 'Bad traffic!']\n",
    "\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "embeddings = model.encode(sentences)\n",
    "# print (embeddings[0][:10])\n",
    "\n",
    "similarity1 = cos_sim(embeddings[0], embeddings[1])\n",
    "# print (similarity1)\n",
    "print (f\"Cosine between\\n{sentences[0]}\\n{sentences[1]}\")\n",
    "print (similarity1.tolist()[0][0])\n",
    "print()\n",
    "\n",
    "print (f\"Cosine between\\n{sentences[0]}\\n{sentences[2]}\")\n",
    "similarity2 = cos_sim(embeddings[0], embeddings[2])\n",
    "# print (similarity2)\n",
    "print (similarity2.tolist()[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-workshop-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
