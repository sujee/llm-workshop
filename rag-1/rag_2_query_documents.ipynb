{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG With llama-index  + Milvus + LLama\n",
    "\n",
    "References\n",
    "- https://docs.llamaindex.ai/en/stable/examples/vector_stores/MilvusIndexDemo/\n",
    "- https://docs.llamaindex.ai/en/stable/api_reference/storage/vector_store/milvus/?h=milvusvectorstore#llama_index.vector_stores.milvus.MilvusVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ config REPLICATE_API_TOKEN found\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "\n",
    "REPLICATE_API_TOKEN = os.environ.get(\"REPLICATE_API_TOKEN\")\n",
    "\n",
    "if  REPLICATE_API_TOKEN:\n",
    "    print (\"✅ config REPLICATE_API_TOKEN found\")\n",
    "else:\n",
    "    raise Exception (\"'❌ REPLICATE_API_TOKEN' is not set.  Please set it above to continue...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Setup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/apps/anaconda3/envs/llm-workshop-2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sujee/apps/anaconda3/envs/llm-workshop-2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = MY_CONFIG.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Connect to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected Llama-index to Milvus instance:  ./rag_1.db\n"
     ]
    }
   ],
   "source": [
    "# connect to vector db\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri = MY_CONFIG.DB_URI ,\n",
    "    dim = MY_CONFIG.EMBEDDING_LENGTH , \n",
    "    collection_name = MY_CONFIG.COLLECTION_NAME,\n",
    "    overwrite=False\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print (\"✅ Connected Llama-index to Milvus instance: \", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Load Document Index from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded index from vector db: ./rag_1.db ,  collection:  walmart\n",
      "CPU times: user 102 ms, sys: 16.8 ms, total: 119 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, storage_context=storage_context)\n",
    "\n",
    "print (\"✅ Loaded index from vector db:\", MY_CONFIG.DB_URI , \",  collection: \", MY_CONFIG.COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.replicate import Replicate\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Replicate(\n",
    "    model= MY_CONFIG.LLM_MODEL,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Query\n",
    "\n",
    "Here are some sample queries based on what dataset you are using.  (You can set the datasets in [my_config.py](my_config.py))\n",
    "\n",
    "**LLM Papers**\n",
    "\n",
    "- What training data was used to train Granite models?\n",
    "- What is attention mechanism\n",
    "\n",
    "**Walmart**\n",
    "\n",
    "- What was Walmart's revenue for 2023?\n",
    "- How many distribution centers does Walmart have?\n",
    "\n",
    "**FOMC**\n",
    "\n",
    "- What is the target inflation rate?\n",
    "- Which members voted?\n",
    "- \n",
    "\n",
    "\n",
    "**And trick question**\n",
    "\n",
    "- When was the moon landing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "According to the provided context information, Walmart's revenue for 2023 was $605,881 million.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What training data was used to train Granite models?\")\n",
    "# res = query_engine.query(\"What was Walmart's revenue for 2023?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Based on the provided context information, Walmart has a total of 163 distribution facilities.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What is attention mechanism\")\n",
    "# res = query_engine.query(\"How many distribution centers does Walmart have?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'm happy to help! However, I don't see any information about the moon landing in the provided context. The context appears to be a 10-K report filed by Walmart Inc. with the Securities and Exchange Commission. There is no mention of the moon landing in this report. If you're looking for information about the moon landing, I'd be happy to help you find it elsewhere!\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"When was the moon landing?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-workshop-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
